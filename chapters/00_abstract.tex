\newcommand{\primarymetric}{66,1}
\newcommand{\secondarymetric}{72,8}

\begin{prefacesection}{Abstract}
    Die Erkennung von Aktionen in Videos, auch \gls{har} genannt, ist Gegenstand aktueller Forschung im Bereich Video Understanding.
    Großspurige Datensets beschränken sich meist auf allgemeine, Domänen-übergreifende Klassen, die eindeutig voneinander abgrenzbar sind und nicht in Kombination auftreten.
    Hingegen finden im Bereich von Feldsportarten, wie Fußball, oft viele, visuell ähnliche Aktionen in kürzester Zeit oder sogar zeitgleich statt.
    Die bestehenden Datensets dieser Domäne bilden bislang nur einen Bruchteil der Spielaktionen aus der realen Welt ab.
    Hier knüpft die vorliegende Arbeit an, in der ein Multi-Label-Datenset mit insgesamt 32 verschiedenen Aktionsklassen, basierend auf TV-Aufzeichnungen von Fußballspielen, neu generiert wird.
    In anschließenden Benchmarks kommen verschiedene Deep-Learning-Architekturen (R2+1D, SlowFast, ir-CSN) als Video-Klassifizierer zum Einsatz, die anhand des neuen Datensets mit Methoden des Transfer-Learnings und ohne weitere Zwischenschritte (\emph{Ende-zu-Ende}) trainiert werden.
    Die Ergebnisse zeigen, dass aktuelle Modelle des Deep-Learnings bereits in der Lage sind, einen Großteil der 32 Klassen hinreichend gut zu erkennen.
    Im Vergleich erreicht ir-CSN hierbei die besten Ergebnisse -- mit einer Balanced Accuracy von \primarymetric \% (\secondarymetric \% bei 24 Klassen).

    \begin{tcolorbox}[title=WIP]
        Weitere Key-Findings: Auflösung und Geschwindigkeit der Videos erwähnen, BA updaten
    \end{tcolorbox}

    The recognition of actions in videos (also Human Action Recognition (HAR)) is the subject of current research in the field of video understanding.
    Large-scale data sets are mostly limited to general, cross-domain classes that are clearly distinguishable from one another and do not occur in combination.
    On the other hand, in the domain of field sports, such as soccer, visually similar actions often take place in a very short time or even at the same time.
    Existing datasets of this domain so far represent only a fraction of the actions from the real world.
    This is where the thesis starts by creating a multi-label dataset with a total of 32 different action classes included, based on TV recordings of soccer matches.
    In the subsequent benchmarks, various Deep Learning architectures (R2+1D, SlowFast, ir-CSN) are used as video classifiers, which are trained end-to-end on the new dataset with methods of transfer learning and without further intermediate steps.
    The results show that current Deep Learnings models are already able to recognize a large part of the 32 classes sufficiently well.
    In comparison, ir-CSN achieved the best results - with a balanced accuracy of \primarymetric \% (\secondarymetric \% in 24 classes).

\end{prefacesection}